{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning and Inverse Problems\n",
    "### Summer 2025\n",
    "### Reinhard Heckel\n",
    "## **Chapter 6 exercise**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising Images with a U-Net\n",
    "\n",
    "In this exercise, your task is to train a U-Net for image denoising using PyTorch. As dataset, we use the Berkeley Segmentation Dataset (BSDS300). This dataset contains 300 clean color images. For simplicity, we consider Gaussian noise and convert the images to grayscale (see below). The attached file `unet.py` contains a PyTorch implemenation of the U-Net for you to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Dataset\n",
    "Running these commands in the terminal downloads the BSDS300 dataset as a `.tgz` file, unzip it and delete the `.tgz` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/BSDS300-images.tgz\n",
    "#!tar -xvzf BSDS300-images.tgz\n",
    "#!rm BSDS300-images.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Google Colab\n",
    "If you want to use google colab for free GPU use, you can copy the notebook, unet.py and the dataset to your google drive (here in directory 'Colab Notebooks'), and mount the drive like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /content/drive/MyDrive/'Colab Notebooks'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages\n",
    "We want you to use PyTorch in this exercise, as it is the most common library for deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import tqdm  # for nice progress bars\n",
    "from matplotlib import pyplot as plt\n",
    "# TODO: maybe you want to use additional libraries\n",
    "\n",
    "from unet import Unet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build PyTorch Datasets and Dataloaders\n",
    "\n",
    "We use all 200 images in `./BSDS300/images/train` for training. The first 50 images in `./BSDS300/images/test` are used for validation and the remaining 50 for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"./BSDS300\"\n",
    "\n",
    "train_set_dir = f\"{dataset_dir}/images/train\"\n",
    "train_img_files = [f\"{train_set_dir}/{filename}\" for filename in os.listdir(train_set_dir)]\n",
    "# use this to train with fewer data\n",
    "# train_img_files = random.sample(train_img_files, 50)\n",
    "\n",
    "test_set_dir = f\"{dataset_dir}/images/test\"\n",
    "test_img_files = [f\"{test_set_dir}/{filename}\" for filename in os.listdir(test_set_dir)]\n",
    "val_img_files = test_img_files[:50]\n",
    "test_img_files = test_img_files[50:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "We first implement a `torch.utils.data.Dataset` that returns pairs of noisy images and clean ground truth. \n",
    "\n",
    "Complete the code below so that the dataset returns images that are **grayscale** (BSDS contains RGB images, so you have to convert them) with pixel-range $[0,1]$. Add zero-mean Gaussian noise with variance `noise_var` to the clean images. To reduce computational cost, we also want to be able to use chunks instead of full-sized images for training. Therefore, implement code to split an image into non-overlapping chunks of size `(chunk_size, chunk_size)`. For example: An image of size `(512, 512)` should be split into 16 non-overlapping chunks of size `(128,128)`. If any of the image dimension is not divisible by `chunk_size`, simply crop the dimension until it is divisble by `chunk_size`. For reference: If you split all 200 train images into chunks of size `(128,128)`, you should end up with 1200 chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyImageChunkDataset(Dataset):\n",
    "    def __init__(self, img_files, noise_var, chunk_size):\n",
    "        self.img_files = img_files\n",
    "        self.noise_var = noise_var\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunks_clean, self.chunks_noisy = self.get_clean_and_noisy_chunks()\n",
    "\n",
    "    def get_clean_and_noisy_chunks(self):\n",
    "        # TODO\n",
    "        return chunks_clean, chunks_noisy\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.chunks_clean)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.chunks_noisy[idx], self.chunks_clean[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_var = 0.005  # more noise makes denoising harder; we suggest you keep this value but you can also experiment with more or less noise\n",
    "train_chunk_size = ?  # depends on your hardware; larger chunks require more memory during gradient computation; we recommend 128\n",
    "\n",
    "train_set = NoisyImageChunkDataset(img_files=train_img_files, noise_var=noise_var, chunk_size=train_chunk_size)\n",
    "# for validation and testing, we do not have to split the images into chunks because we do not have to compute gradients\n",
    "# the images have shape (321, 481) or (481, 321) so we crop them to (321, 321) to facilitate data loading\n",
    "val_set = NoisyImageChunkDataset(img_files=val_img_files, noise_var=noise_var, chunk_size=321)\n",
    "test_set = NoisyImageChunkDataset(img_files=test_img_files, noise_var=noise_var, chunk_size=321)\n",
    "\n",
    "plt.imshow(train_set[0][0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = ?  # depends on your hardware\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more pooling layers and convolutional kernels increase the complexity of the U-Net (see lecture notes)\n",
    "num_pool_layers = ?\n",
    "chans = ?\n",
    "device = \"cpu\"  # set to \"cuda\" or \"cuda:0\" if you have access to a GPU (e.g. via Google Colab)\n",
    "\n",
    "model = Unet(\n",
    "    in_chans=1,  # 1 input channel as we use grayscale images as input\n",
    "    out_chans=1,  # 1 output channel as the model returns grayscale images\n",
    "    num_pool_layers=num_pool_layers,\n",
    "    chans=chans\n",
    ")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "Choose a suitable loss for training and implement the training loop. Be sure to also check the validation loss (or PSNR) every few epochs to be sure that your model does not overfit.\n",
    "\n",
    "Hint: In deep learning it is often helpful to normalize the data before passing it through the model. In image-to-image tasks (such as denoising), we often also de-normalize the model output to map the pixels back into the original range. For example:\n",
    "````\n",
    "mean, std = mean(img_noisy), std(img_noisy)\n",
    "img_noisy = (img-mean) / std\n",
    "img_denoised = model(img_noisy)\n",
    "img_denoised = img_denoised * std + mean\n",
    "````\n",
    "An intuition behind this is that the model can then receive and return images in a fixed range which makes learning easier. Feel free to train your model with and without normalization to see if it makes a difference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = ?  # choose a suitable optimizer form torch.optim; we recommend to use the ADAM optimizer\n",
    "\n",
    "epochs = ?  # how many epochs to train\n",
    "check_val_every_epochs = ?\n",
    "\n",
    "\n",
    "for e in range(epochs):\n",
    "    for imgs_noisy, imgs_clean in tqdm.tqdm(train_loader, desc=\"Training\"):\n",
    "        imgs_noisy = imgs_noisy.to(device)\n",
    "        imgs_clean = imgs_clean.to(device)\n",
    "        #  TODO\n",
    "    \n",
    "    if e % check_val_every_epochs == 0:\n",
    "        # disable gradient computation for validation\n",
    "        with torch.no_grad():\n",
    "            for imgs_noisy, imgs_clean in tqdm.tqdm(val_loader, desc=\"Validation\"):\n",
    "                # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "Test your model on the `test_loader`. Use suitable image metrics (e.g. PSNR, SSIM) to quantitatively assess the denoising performance of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
